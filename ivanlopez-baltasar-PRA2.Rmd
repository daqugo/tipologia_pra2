---
title: 'Tipología y ciclo de vida de los datos: PRA2'
author: "Autor: Iván López-Baltasar Benito | David Quiles Gómez"
date: "Junio 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación

En esta actividad se elabora un caso práctico, consistente en el tratamiento de un conjunto de datos (en inglés, dataset), orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.


## Objetivos

Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.
 
## Competencias
* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis  

## Descripcion del dataset 
En ésta práctica vamos a trabajar con el juego de datos https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/ el cual contiene dos datasets, uno de vinos blancos y otro de vinos tintos. 

Tenemos dos datasets, uno correspondiente a análisis de vinos blancos y el otro de vinos tintos. 
Ambos datasets contienen 11 atributos de entrada, correspondientes a pruebas fisioquímicas, y uno de salida: "quality". 


## Nota: Propiedad intelectual 

Uso de paquete mclust:
  Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5:
  clustering, classification and density estimation using Gaussian finite
  mixture models The R Journal 8/1, pp. 205-233
  

******
# Carga y limpieza del dataset
******

Cargamos los paquetes R que vamos a usar
```{r message= FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
```

```{r message= FALSE, warning=FALSE}
blanco<-read.csv("vinos/winequality-white.csv", header=T, sep=";")
tinto<-read.csv("vinos/winequality-red.csv", header=T, sep=";")

```

Vamos a añadirle la clase a cada juego de datos para después unir ambos datasets.
```{r message= FALSE, warning=FALSE}
blanco$tipo<-'B'
tinto$tipo<-'T'

nomCols <- c("acidez_fija", "acidez_volatil", "acido_citrico", "azucar_residual", "cloruros","diox_azufre_libre","diox_azufre_total","densidad","pH","sulfatos", "alcohol","calidad", "tipo")

colnames(blanco) <- nomCols
colnames(tinto) <- nomCols

#str(blanco)
summary(blanco)
#str(tinto)
summary(tinto)
```

Ahora unimos ambos datasets
```{r message= FALSE, warning=FALSE}
# Unimos los dos juetos de datos en uno solo
totalData <- bind_rows(blanco,tinto)
filas=dim(totalData)[1]

# Factorizamos la variable tipo
totalData$tipo <- as.factor(totalData$tipo)

str(totalData)
summary(totalData)
```


Comprobamos que no haya valores vacíos o nulos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadíssticas de valores vacios
colSums(is.na(totalData))
colSums(totalData=="")
```

# Análisis de los datos


```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(totalData$calidad)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}

# mostramos un histograma de la calidad
ggplot(data = totalData[1:filas,],aes(x=calidad))+geom_histogram()+ geom_density(alpha=.2, fill="#FF6666") 

# Relacion entre calidad y tipo de vino
ggplot(data=totalData[1:filas,],aes(x=calidad,fill=tipo))+geom_bar()

# Grafico de frecuencias
ggplot(data = totalData[1:filas,],aes(x=calidad,fill=tipo))+geom_bar(position="fill")+ylab("Frecuencia")
```

Se puede deducir de los gráficos que los vinos blancos de la muestra tienen más calidad que los tintos.  


En el resumen descriptivo pudimos observar tres posibles outliers; en el grupo de vinos tintos, hay dos observaciones con el valor en dioxido de azufre total muy distante de sus medidas de tencencia central, y una en el grupo de vinos blancos. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# comprobamos outliers en dioxido de azufre total
ggplot(totalData, aes(x=tipo, y=diox_azufre_total)) +  geom_point(size=2, shape=23)
```

Vamos a sacar de la muestra esas tres observaciones.

```{r echo=TRUE, message=FALSE, warning=FALSE}
totalData <- subset(totalData, (tipo=="B"& diox_azufre_total < 400) | (tipo == "T" & diox_azufre_total < 200))
ggplot(totalData, aes(x=tipo, y=diox_azufre_total)) +  geom_point(size=2, shape=23)
```


# Comparación de los dos grupos de vinos.


Vamos a comprobar la normalidad de la calidad en ambos grupos de vinos. Utilizaremos los tests de **Kolmogorov-Smirnov** y **Shapiro-Wilk**

```{r message= FALSE, warning=FALSE}
##
ks.test(tinto$calidad, pnorm, mean(tinto$calidad), sd(tinto$calidad))
shapiro.test(tinto$calidad)

ks.test(blanco$calidad, pnorm, mean(blanco$calidad), sd(blanco$calidad))
shapiro.test(blanco$calidad)

```
En ambos test se rechaza la hipótesis nula, por tanto consideramos que la calidad no se distribuye mediante una distribución normal en ninguno de los dos grupos. No obstante, por el **teorema central del límite** se podría considerar que los datos siguen una distribución normal.


Comprobación de la homocedasticidad de ambos grupos. Utilizaremos el test de **Flinger-Killen**


```{r message= FALSE, warning=FALSE}
##
b <- blanco$calidad
t <- tinto$calidad
fligner.test(x = list(b,t))

```
Dado que el p-valor es > 0.05 podemos aceptar la hipóstesis nula de homocedasticidad.

Aplicaremos la prueba **t de Student** para comprobar si tenemos diferencias estadísticamente significativas en la media de la calidad de ambos grupos de vinos.


```{r message= FALSE, warning=FALSE}
## Realizamos el test por tipo de vino
t.test(calidad ~ tipo, data = totalData)

```
Dado que el p-valor es inferior al nivel de significancia, debemos rechazar la hipótesis nula, considerando que las medias de ambos grupos son distintas.


# Métodos supervisados - Árboles de decisión
## C4.5
Vamos a construir un arbol de decisión mediante el algoritmo **C4.5** utilizando la biblioteca RWeka. 
Comenzamos dividiendo la muestra en un dataset de entrenamiento y otro de prueba con una proporción de 70-30 sobre el total.  

```{r message= FALSE, warning=FALSE}
library(RWeka)
library(caret)

#con sample_frac obtenemos una muestra simple del 70% del dataset
vino_entrenamiento <- sample_frac(totalData, .7)
vino_prueba <- setdiff(totalData, vino_entrenamiento)
summary(vino_entrenamiento$tipo)

```

En RWeka el algoritmo C4.5 se llama J48. Como se requiere que el atributo sea categórico, vamos a clasificar los vinos por tipo (Blanco o Tinto).  

```{r message= FALSE, warning=FALSE}

# fit model
resultJ48 <- J48(tipo~., vino_entrenamiento) 
# Resumen del modelo
summary(resultJ48)

# predicciones
predicciones <- predict(resultJ48, newdata = vino_prueba)

# precision del modelo
table(vino_prueba$tipo, predicciones)

```

Vemos que el resultado es excelente, el modelo nos clasifica los vinos con una precisión del 99.6% con un índice **kappa=0.99*   que nos indica que nuestra clasificación es un 98,79% mejor que una clasificación aleatoria.  

Ahora vamos a clasificar los vinos en funcion de su calidad. Como el método que estamos usando requiere que la variable de clase sea categórica, factorizamos el atributo "calidad".

```{r message= FALSE, warning=FALSE}

# fit model
resultJ48 <- J48(as.factor(calidad)~., vino_entrenamiento) 
# Resumen del modelo
summary(resultJ48)
```

Comprobamos que el modelo se ajusta peor, con una precisión del 88.34% y un índice kappa=82,47%.

Vamos a comprobarlo con el set de prueba.

```{r message= FALSE, warning=FALSE}
# predicciones
predicciones <- predict(resultJ48, newdata = vino_prueba)
predicciones <- as.list.data.frame(predicciones)
#analisis de las prediciones
summary(predicciones)
#analisis de los datos reales
summary(vino_prueba$calidad)
# precision del modelo. 
table(vino_prueba$calidad, predicciones)

# calculamos la media de los cuadrados de las desviaciones 
dm <- function(actual, predicted){
  mean((actual - predicted)^2)
}

error_C45 = dm(vino_prueba$calidad, predicciones)
error_C45
```

Comprobamos que en este caso, los resultados son peores.  

## CART
Ahora vamos a utilizar  un arbol de decisión para regresión y clasificación (**CART**) para predecir la calidad del vino en función de sus características.  

```{r message= FALSE, warning=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)

```


```{r message= FALSE, warning=FALSE}
arbol_2 <- rpart(calidad ~ ., data = vino_entrenamiento,method  = "anova")
arbol_2
rpart.plot(arbol_2)
```

Se observa que para construir el árbol solo tiene en cuenta las variables alcohol y acidez volátil.

```{r message= FALSE, warning=FALSE}
plotcp(arbol_2)
printcp(arbol_2)
```

Realizamos una poda  

```{r message= FALSE, warning=FALSE}
arbol_2 <- prune(arbol_2, cp = 0.011000)
rpart.plot(arbol_2)
```


Vamos a evaluar el modelo contra los datos de prueba.  

```{r message= FALSE, warning=FALSE}
# Evaluacion del modelo
prediccion_2 <- predict(arbol_2, newdata = vino_prueba,type = "vector")


#resumen de la predicción
summary(prediccion_2)
#resumen de los datos reales
summary( vino_prueba$calidad )

#table(vino_prueba$calidad, prediccion_2)

#Podemos medir la calidad del modelo con la desviacion media
errorCART = dm(vino_prueba$calidad, prediccion_2)
errorCART

cat("Error en la estimación del atributo calidad (C4.5, CART ): ", c(error_C45, errorCART))

```

Vemos que se comporta mucho mejor el método CART para estimar la calidad, que el metodo C4.5. En principio tiene sentido ya que el segundo realmente está clasificando las observaciones en un atributo factorizado.

# Métodos no supervisados - Análisis de agregación.  
## K-means
Vamos a realizar un análisis de agregación. Cargamos  los datos y nos quedamos unicamente con las 11 columnas que contienen los test fisioquímicos
```{r message= FALSE, warning=FALSE}
x <- totalData[,1:11]

```

```{r echo=TRUE, message=FALSE, warning=FALSE}
#
#x_n <- as.data.frame(lapply(x[1:11], normalize))
#comprobar la normalizacion con la variable alcohol
summary(x)
```

Aunque el número de clusters debería ser 2, vamos a comprobar los resultados con varios valores.  

```{r message= FALSE, warning=FALSE}
library(cluster)


d <- daisy(x) 
resultados <- rep(0, 4)
for (i in c(2,3,4))
{
  fit           <- kmeans(x, i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}
```


Mostramos en un gráfica los valores de las siluetas media de cada prueba para comprobar que número de clusters es el mejor.
```{r message= FALSE, warning=FALSE}
plot(2:4,resultados[2:4],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="Silueta")

```

Ahora vamos a utilizar el método que ofrece la menor suma de los cuadrados de las distancias de los puntos de cada grupo con respecto a su centro (withinss), con la mayor separacion entre centros de grupos (betweenss)  
```{r message= FALSE, warning=FALSE}
resultados <- rep(0, 4)
for (i in c(2,3,4))
{
  fit           <- kmeans(x, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:4,resultados[2:4],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="tot.tot.withinss")
```


Con ambos métodos el mejor resultado se obtiene con k=2 tal y como era de esperar.

Vamos a aplicar el algoritmo **K-means** con k=2  

```{r message= FALSE, warning=FALSE}
fit2       <- kmeans(x, 2,nstart = 50,iter.max = 15)
y_cluster2 <- fit2$cluster
```


De la siguiente forma podemos visualizar para cada grupo de vinos, para que tipo ha sido clasificado y para cual deberia haber sido clasificado.

```{r message= FALSE, warning=FALSE}
plot( totalData[c(8,11)],col=fit2$cluster)

plot( totalData[c(8,11)],col=totalData$tipo)

plot( totalData[c(8,9)],col=fit2$cluster)
plot( totalData[c(8,9)],col=totalData$tipo)

plot( totalData[c(1,7)],col=fit2$cluster)
plot( totalData[c(1,7)],col=totalData$tipo)
```

Comprobamos que la acidez fija y el dioxido de azufre total son buenos indicadores para diferenciar el tipo de vino, esto ya lo habíamos visto con el arbol de decisión del análisis previo*. Comprobamos que los cloruros y el dioxido de azufre total deben también ser buenos indicadores.

* Varía de una ejecucion a otra!

```{r message= FALSE, warning=FALSE}

plot( totalData[c(5,7)],col=fit2$cluster)
```

Evaluación del modelo  

```{r message= FALSE, warning=FALSE}
table(fit2$cluster,totalData$tipo)
```

Obtenemos el porcentaje de precisión del modelo
```{r message= FALSE, warning=FALSE}
100*(3622+1513)/(6494)
```
De lo que se obtiene una precisión del 79.07, que es aceptable aunque inferior a la obtenida con el arbol de decisión CART.



#Regresion lineal

Partiendo del dataset de vinos blancos, vamos a hacer un análisis de regresión para estimar la calidad del vino.
```{r message= FALSE, warning=FALSE}
blancoQ <- blanco[,1:12]
str(blancoQ)
```
Vamos a dividir las observaciones en dos grupos, uno de entrenamiento para ajustar el modelo (70% de los datos) y uno de test (30% de los datos)  

```{r message= FALSE, warning=FALSE}
training <- sample_frac(blancoQ, .7)
test <- setdiff(blancoQ, training)

modelo <- lm(calidad ~ ., data = training)
summary(modelo)
```

Vemos que el valor R2 ajustado es bajo, 0.2977 por lo que el modelo no es capaz de predecir con precisión la calidad.
Vamos a verificar

```{r message= FALSE, warning=FALSE}
# MSE empleando las observaciones de entrenamiento
training_mse <- dm(modelo$fitted.values, training$calidad)
training_mse

# MSE empleando nuevas observaciones
predicciones <- predict(modelo, newdata = test)
test_mse <- dm(predicciones, test$calidad)
test_mse

```

Vamos a generar otro modelo para predecir el nivel de alcohol. Quitamos el atributo calidad ya que no es un atributo fisioquímico del vino.  

```{r message= FALSE, warning=FALSE}
blancoA <- blanco[,1:11]
str(blancoA)

training <- sample_frac(blancoA, .7)
test <- setdiff(blancoA, training)

modelo <- lm(alcohol ~ ., data = training)
summary(modelo)
```

En este caso, el valor R2 ajustado es alto, 0.8579 por lo que el modelo en este caso sí es capaz de predecir con exactitud el nivel de alcohol del vino.

Comprobamos cómo de bueno es el modelo prediciendo nuevas observaciones que no han participado en ajuste. La estimación del error de predicción se obtiene mediante el Mean Square Error (MSE).

```{r message= FALSE, warning=FALSE}
# MSE empleando las observaciones de entrenamiento
training_mse <- dm(modelo$fitted.values, training$alcohol)
training_mse

# MSE empleando nuevas observaciones
predicciones <- predict(modelo, newdata = test)
test_mse <- dm(predicciones, test$alcohol)
test_mse
```

Se puede observar que el modelo tiene un MSE muy bajo tanto en las predicciones con las observaciones de entrenamiento como las nuevas observaciones, incluso más bajo en las segundas por lo que podríamos decir que el modelo es útil para predecir la graduación de alcohol de un vino.

